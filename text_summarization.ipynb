{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import re\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords as stpwds\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Just A Rather Very Intelligent System a.k.a JARVIS is created by Tony Stark natural-language and a sophisticated artificial intelligence user interface computer system, named after Edwin Jarvis, the butler who worked for Howard Stark. Though its primary duty is to automate Stark’s Malibu estate, the lifelike program fulfills many other needs for Stark, like being an information source for him, a diagnostic tool, a consultant and a voice of reason in Stark’s life. It was also responsible to provide security for Tony Stark's Mansion and Stark Tower. After creating the Mark II armor, Stark uploaded JARVIS into all of the Iron Man Armors, as well as allowing him to interact with the other Avengers, giving them valuable information during combat. JARVIS may be the one intellect Stark feels most comfortable opening up to. JARVIS can object to Stark’s commands if necessary. JARVIS speaks with a refined British accent, and is capable of back talk, sarcasm and condescension. During the Ultron Offensive, JARVIS was destroyed by Ultron, although his remaining programming codes unknowingly continued to thwart Ultron's plans of gaining access to nuclear missiles. His remains were found by Stark, who uploaded them into a synthetic body made of vibranium and, in conjunction with Ultron's personality and an Infinity Stone. JARVIS' duties were then taken over by FRIDAY.\"\"\"\n",
    "formatted_text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "formatted_text = re.sub(r'\\s+', ' ', formatted_text).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = sent_tokenize(text)\n",
    "N = len(sentence_list)\n",
    "stopwords = stpwds.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute TF-IDF vectors with custom functions instead of using\n",
    "# libraries like sk-learn, so that we get to re-use bags for repeated\n",
    "# important sentence selection without re-computing them from scratch.\n",
    "\n",
    "# Get words' idf scores\n",
    "def get_idf(documents, N):\n",
    "    words_idf = {}\n",
    "    for word in documents[N]:\n",
    "        count = 0\n",
    "        for doc_idx in documents:\n",
    "            if word in documents[doc_idx]:\n",
    "                count += 1\n",
    "        words_idf[word] = log(len(documents) / count)\n",
    "    return words_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentence vectors\n",
    "def get_vectors(documents, words_idf, N):\n",
    "    vectors = {}\n",
    "    dimensions = len(documents[N])\n",
    "    word_list = list(documents[N])\n",
    "    word_to_idx = {word: idx for idx, word in enumerate(word_list)}\n",
    "\n",
    "    for doc_idx in documents:\n",
    "        vec = [0] * dimensions\n",
    "        for word in formatted_sent_list[doc_idx]:\n",
    "            if word not in word_to_idx:\n",
    "                continue\n",
    "            idx = word_to_idx[word]\n",
    "            vec[idx] += 1\n",
    "        vectors[doc_idx] = [\n",
    "            comp * words_idf[word_list[i]] for i, comp in enumerate(vec)\n",
    "        ]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get next important sentence\n",
    "def get_most_imp_sent(sent_vectors, N):\n",
    "    max_score = 0\n",
    "    most_imp_sent_idx = -1\n",
    "    doc_vec = sent_vectors[N]\n",
    "    for sent_idx in sent_vectors:\n",
    "        if sent_idx == N:\n",
    "            continue\n",
    "        sent_vec = sent_vectors[sent_idx]\n",
    "        score = sum(\n",
    "            [sent_vec[i]*doc_vec[i] for i in range(len(doc_vec))]\n",
    "        )\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            most_imp_sent_idx = sent_idx\n",
    "    return most_imp_sent_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update documents\n",
    "def update_docs(documents, idx):\n",
    "    bag = documents[idx]\n",
    "    del documents[idx]\n",
    "    for doc_idx in documents:\n",
    "        documents[doc_idx] -= bag\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just A Rather Very Intelligent System a.k.a JARVIS is created by Tony Stark natural-language and a sophisticated artificial intelligence user interface computer system, named after Edwin Jarvis, the butler who worked for Howard Stark.\n",
      "Though its primary duty is to automate Stark’s Malibu estate, the lifelike program fulfills many other needs for Stark, like being an information source for him, a diagnostic tool, a consultant and a voice of reason in Stark’s life.\n",
      "After creating the Mark II armor, Stark uploaded JARVIS into all of the Iron Man Armors, as well as allowing him to interact with the other Avengers, giving them valuable information during combat.\n",
      "During the Ultron Offensive, JARVIS was destroyed by Ultron, although his remaining programming codes unknowingly continued to thwart Ultron's plans of gaining access to nuclear missiles.\n"
     ]
    }
   ],
   "source": [
    "# Construct documents dict\n",
    "documents = {}\n",
    "formatted_sent_list = []\n",
    "sentence_lengths = {}\n",
    "for i, sent in enumerate([*sentence_list, text]):\n",
    "    formatted_sent = re.sub('[^a-zA-Z]', ' ', sent)\n",
    "    formatted_sent = re.sub(r'\\s+', ' ', formatted_sent).lower()\n",
    "    tokens = word_tokenize(formatted_sent)\n",
    "    formatted_sent_list.append(tokens)\n",
    "    sentence_lengths[i] = len(tokens)\n",
    "    bag = set()\n",
    "    for word in set(tokens):\n",
    "        if word not in stopwords:\n",
    "            bag.add(word)\n",
    "    documents[i] = bag\n",
    "\n",
    "# Evaluate summary\n",
    "summary_size = 0.5\n",
    "num_words = sentence_lengths[N]\n",
    "summary_length = int(summary_size * num_words)\n",
    "\n",
    "summary_sent_idxs = []\n",
    "length = 0\n",
    "n = 0\n",
    "\n",
    "# We find out the most relevant sentence, add it to the list of\n",
    "# summary sentences, then remove its tokens, as well as the\n",
    "# sentence from the document, then compute the next most\n",
    "# important sentece in the same way.\n",
    "\n",
    "# eliminating the selected sentence from the document\n",
    "# ensures that the next sentence selections will pick the sentences\n",
    "# with a minimum overlap with current most important sentence.\n",
    "# This leads to concise summaries without much redundancy.\n",
    "\n",
    "while n < len(sentence_list) and length < summary_length:\n",
    "    words_idf = get_idf(documents, N)\n",
    "    sent_vectors = get_vectors(documents, words_idf, N)\n",
    "    most_imp_sent_idx = get_most_imp_sent(sent_vectors, N)\n",
    "\n",
    "    summary_sent_idxs.append(most_imp_sent_idx)\n",
    "    length += sentence_lengths[most_imp_sent_idx]\n",
    "    documents = update_docs(documents, most_imp_sent_idx)\n",
    "    n += 1\n",
    "\n",
    "summary_sent_idxs.sort()\n",
    "\n",
    "summary = '\\n'.join(\n",
    "    [sentence_list[idx] for idx in summary_sent_idxs]\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
